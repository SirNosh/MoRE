{
    "name": "huginn_raven_700m",
    "architectures": [
        "RavenForCausalLM"
    ],
    "auto_map": {
        "AutoConfig": "raven_config_minimal.RavenConfig",
        "AutoModelForCausalLM": "raven_modeling_minimal.RavenForCausalLM"
    },
    "torch_dtype": "bfloat16",
    "transformers_version": "4.47.1",
    "hf_config": {
        "org": "tomg-group-umd",
        "name": "huginn_raven_700m"
    },
    "model_type": "huginn_raven_700m",
    "block_size": 4096,
    "vocab_size": 65536,
    "padding_multiple": 4096,
    "tie_embeddings": true,
    "num_attention_heads": 12,
    "n_embd": 1536,
    "intermediate_size": 14336,
    "bias": false,
    "architecture_class_name": "RecurrentGPT",
    "block_class_name": "SandwichBlock",
    "norm_class_name": "RMSNorm_llama",
    "norm_eps": 1e-06,
    "mlp_class_name": "GatedMLP",
    "nonlin_name": "SiLU",
    "init_strategy": "takase",
    "init_orthogonal": false,
    "state_init": "like-init",
    "injection_type": "linear",
    "n_layers_in_recurrent_block": 4,
    "mean_recurrence": 32,
    "sampling_scheme": "poisson-lognormal-filling",
    "mean_backprop_depth": 8,
    "n_layers_in_prelude": 2,
    "n_layers_in_coda": 2,
    "qk_bias": true,
    "activation_checkpoint_impl": "per-iteration"
}